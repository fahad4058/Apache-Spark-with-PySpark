{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "sqlcontext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll=spark.createDataFrame([(1,\"pollingtilte\",\"2020\",\"2021\",\"pti\",\"people\")]).toDF(\"poll_id\",\"title\",\"startDate\",\"endDate\",\"organzier\",\"participants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+---------+-------+---------+------------+\n",
      "|poll_id|       title|startDate|endDate|organzier|participants|\n",
      "+-------+------------+---------+-------+---------+------------+\n",
      "|      1|pollingtilte|     2020|   2021|      pti|      people|\n",
      "+-------+------------+---------+-------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poll.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=spark.createDataFrame([(0,\"questiontitle\",\"subjective\",1)]).toDF(\"question_id\",\"title\",\"type\",\"poll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+----+\n",
      "|question_id|        title|      type|poll|\n",
      "+-----------+-------------+----------+----+\n",
      "|          0|questiontitle|subjective|   1|\n",
      "+-----------+-------------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll.createOrReplaceTempView(\"polls\")\n",
    "question.createOrReplaceTempView(\"questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(6) Sort [startDate#14 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(startDate#14 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#200]\n",
      "   +- *(5) SortMergeJoin [poll#60L], [cast(poll_id#12 as bigint)], Inner\n",
      "      :- *(2) Sort [poll#60L ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(poll#60L, 200), ENSURE_REQUIREMENTS, [id=#187]\n",
      "      :     +- *(1) Project [_1#49L AS question_id#57L, _2#50 AS title#58, _3#51 AS type#59, _4#52L AS poll#60L]\n",
      "      :        +- *(1) Filter isnotnull(_4#52L)\n",
      "      :           +- *(1) Scan ExistingRDD[_1#49L,_2#50,_3#51,_4#52L]\n",
      "      +- *(4) Sort [cast(poll_id#12 as bigint) ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(cast(poll_id#12 as bigint), 200), ENSURE_REQUIREMENTS, [id=#193]\n",
      "            +- *(3) Project [_1#0 AS poll_id#12, _2#1 AS title#13, _3#2 AS startDate#14, _4#3 AS endDate#15, _5#4 AS organzier#16, _6#5 AS participants#17]\n",
      "               +- *(3) Filter isnotnull(_1#0)\n",
      "                  +- *(3) Scan ExistingRDD[_1#0,_2#1,_3#2,_4#3,_5#4,_6#5]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM questions INNER JOIN polls on (polls.poll_id)=(questions.poll) ORDER BY startDate ; \"\"\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(6) Sort [startDate#14 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(startDate#14 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#670]\n",
      "   +- *(5) Project [poll_id#12, startDate#14, endDate#15, question_id#57L, type#59]\n",
      "      +- *(5) SortMergeJoin [poll#60L], [cast(poll_id#12 as bigint)], Inner\n",
      "         :- *(2) Sort [poll#60L ASC NULLS FIRST], false, 0\n",
      "         :  +- Exchange hashpartitioning(poll#60L, 200), ENSURE_REQUIREMENTS, [id=#656]\n",
      "         :     +- *(1) Project [_1#49L AS question_id#57L, _3#51 AS type#59, _4#52L AS poll#60L]\n",
      "         :        +- *(1) Filter isnotnull(_4#52L)\n",
      "         :           +- *(1) Scan ExistingRDD[_1#49L,_2#50,_3#51,_4#52L]\n",
      "         +- *(4) Sort [cast(poll_id#12 as bigint) ASC NULLS FIRST], false, 0\n",
      "            +- Exchange hashpartitioning(cast(poll_id#12 as bigint), 200), ENSURE_REQUIREMENTS, [id=#662]\n",
      "               +- *(3) Project [_1#0 AS poll_id#12, _3#2 AS startDate#14, _4#3 AS endDate#15]\n",
      "                  +- *(3) Filter isnotnull(_1#0)\n",
      "                     +- *(3) Scan ExistingRDD[_1#0,_2#1,_3#2,_4#3,_5#4,_6#5]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQL query\n",
    "spark.sql(\"\"\"SELECT poll_id,startDate,endDate,question_id,type FROM questions INNER JOIN polls ON (questions.poll)=(polls.poll_id)\\\n",
    "ORDER BY startDate ;\"\"\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
