{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "sqlcontext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Book Reference\n",
    "\n",
    "## JOINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually creating a dataframe\n",
    "\n",
    "## Syntax\n",
    "## DF=spark.createDataFrame(RDD,Columns)\n",
    "## preferable\n",
    "\n",
    "personDF=spark.createDataFrame([(0,\"Bill chambers\",0),(1,\"Matt Armbrust\",1)]).toDF(\"id\",\"name\",\"Graduate_program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- Graduate_program: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "personDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Second way\n",
    "personRDD=sc.parallelize([(0,\"Bill chambers\",0),(1,\"Matt Armbrust\",1)])\n",
    "personCol=[\"id\",\"name\",\"Graduate_program\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "personDF=spark.createDataFrame(personRDD,personCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+\n",
      "| id|         name|Graduate_program|\n",
      "+---+-------------+----------------+\n",
      "|  0|Bill chambers|               0|\n",
      "|  1|Matt Armbrust|               1|\n",
      "+---+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "personDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- Graduate_program: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "personDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually Create two dataframes and join them\n",
    "person = spark.createDataFrame([\\\n",
    "(0, \"Bill Chambers\", 0, [100]),\\\n",
    "(1, \"Matei Zaharia\", 1, [500, 250, 100]),\\\n",
    "(2, \"Michael Armbrust\", 1, [250, 100])])\\\n",
    ".toDF(\"id\", \"name\", \"graduate_program\", \"spark_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+\n",
      "| id|            name|graduate_program|   spark_status|\n",
      "+---+----------------+----------------+---------------+\n",
      "|  0|   Bill Chambers|               0|          [100]|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|\n",
      "+---+----------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually Creating Dataframes\n",
    "\n",
    "graduateProgram = spark.createDataFrame([\\\n",
    "(0, \"Masters\", \"School of Information\", \"UC Berkeley\"),\\\n",
    "(2, \"Masters\", \"EECS\", \"UC Berkeley\"),\\\n",
    "(1, \"Ph.D.\", \"EECS\", \"UC Berkeley\")])\\\n",
    ".toDF(\"id\", \"degree\", \"department\", \"school\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+\n",
      "| id| degree|          department|     school|\n",
      "+---+-------+--------------------+-----------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  2|Masters|                EECS|UC Berkeley|\n",
      "|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graduateProgram.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkStatus = spark.createDataFrame([\\\n",
    "(500, \"Vice President\"),\\\n",
    "(250, \"PMC Member\"),\\\n",
    "(100, \"Contributor\")])\\\n",
    ".toDF(\"id\", \"status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+\n",
      "| id|        status|\n",
      "+---+--------------+\n",
      "|500|Vice President|\n",
      "|250|    PMC Member|\n",
      "|100|   Contributor|\n",
      "+---+--------------+\n",
      "\n",
      "+---+-------+--------------------+-----------+\n",
      "| id| degree|          department|     school|\n",
      "+---+-------+--------------------+-----------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  2|Masters|                EECS|UC Berkeley|\n",
      "|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "+---+-------+--------------------+-----------+\n",
      "\n",
      "+---+----------------+----------------+---------------+\n",
      "| id|            name|graduate_program|   spark_status|\n",
      "+---+----------------+----------------+---------------+\n",
      "|  0|   Bill Chambers|               0|          [100]|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|\n",
      "+---+----------------+----------------+---------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkStatus.show(),graduateProgram.show(),person.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#normal join example \n",
    "person.join(graduateProgram,person[\"graduate_program\"]==graduateProgram[\"id\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the lecture notes\n",
    "\n",
    "#### Performing Joins with spark queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating two dataframes to perform join operations\n",
    "person_DF=spark.createDataFrame([(0,\"Bill chambers\",0),\\\n",
    "                                 (1,\"Matt Armbrust\",1)]).toDF(\"id\",\"name\",\"graduate_program\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_DF=spark.createDataFrame([(0,\"Masters\",\"MIT\"),\\\n",
    "                                  (1,\"PHD\",\"MIT\"),\\\n",
    "                                  (2,\"PHD\",\"UCB\")]).toDF(\"id\",\"degree\",\"school\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+\n",
      "| id|         name|graduate_program|\n",
      "+---+-------------+----------------+\n",
      "|  0|Bill chambers|               0|\n",
      "|  1|Matt Armbrust|               1|\n",
      "+---+-------------+----------------+\n",
      "\n",
      "+---+-------+------+\n",
      "| id| degree|school|\n",
      "+---+-------+------+\n",
      "|  0|Masters|   MIT|\n",
      "|  1|    PHD|   MIT|\n",
      "|  2|    PHD|   UCB|\n",
      "+---+-------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the two dataframes are as follows\n",
    "person_DF.show(),program_DF.show() #Left=person and right=program datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########For later\n",
    "# creating tempView for performing join through SQL queries\n",
    "#person_DF.createOrReplaceTempView(\"person\")\n",
    "#program_DF.createOrReplaceTempView(\"program\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Join: It joins the left and right datasets based on the common keys/column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+\n",
      "| id|         name|graduate_program|\n",
      "+---+-------------+----------------+\n",
      "|  0|Bill chambers|               0|\n",
      "|  1|Matt Armbrust|               1|\n",
      "+---+-------------+----------------+\n",
      "\n",
      "+---+-------+------+\n",
      "| id| degree|school|\n",
      "+---+-------+------+\n",
      "|  0|Masters|   MIT|\n",
      "|  1|    PHD|   MIT|\n",
      "|  2|    PHD|   UCB|\n",
      "+---+-------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, name: string, graduate_program: bigint, id: bigint, degree: string, school: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing \"natural\" join operation with spark query\n",
    "person_DF.show(),program_DF.show()\n",
    "person_DF.join(program_DF,person_DF[\"graduate_program\"]==program_DF[\"id\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner Joins: Based on the keys in the left and datasets, joins the rows with common keys and discards the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+\n",
      "| id|         name|graduate_program|\n",
      "+---+-------------+----------------+\n",
      "|  0|Bill chambers|               0|\n",
      "|  1|Matt Armbrust|               1|\n",
      "+---+-------------+----------------+\n",
      "\n",
      "+---+-------+------+\n",
      "| id| degree|school|\n",
      "+---+-------+------+\n",
      "|  0|Masters|   MIT|\n",
      "|  1|    PHD|   MIT|\n",
      "|  2|    PHD|   UCB|\n",
      "+---+-------+------+\n",
      "\n",
      "+---+-------------+----------------+---+-------+------+\n",
      "| id|         name|graduate_program| id| degree|school|\n",
      "+---+-------------+----------------+---+-------+------+\n",
      "|  0|Bill chambers|               0|  0|Masters|   MIT|\n",
      "|  1|Matt Armbrust|               1|  1|    PHD|   MIT|\n",
      "+---+-------------+----------------+---+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performing \"inner\" join operation with spark query \n",
    "person_DF.show(),program_DF.show()\n",
    "person_DF.join(program_DF,person_DF[\"graduate_program\"]==program_DF[\"id\"],\"inner\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer Joins: keeps all the keys in the left and right datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+\n",
      "| id|         name|graduate_program|\n",
      "+---+-------------+----------------+\n",
      "|  0|Bill chambers|               0|\n",
      "|  1|Matt Armbrust|               1|\n",
      "+---+-------------+----------------+\n",
      "\n",
      "+---+-------+------+\n",
      "| id| degree|school|\n",
      "+---+-------+------+\n",
      "|  0|Masters|   MIT|\n",
      "|  1|    PHD|   MIT|\n",
      "|  2|    PHD|   UCB|\n",
      "+---+-------+------+\n",
      "\n",
      "+----+-------------+----------------+---+-------+------+\n",
      "|  id|         name|graduate_program| id| degree|school|\n",
      "+----+-------------+----------------+---+-------+------+\n",
      "|   0|Bill chambers|               0|  0|Masters|   MIT|\n",
      "|   1|Matt Armbrust|               1|  1|    PHD|   MIT|\n",
      "|null|         null|            null|  2|    PHD|   UCB|\n",
      "+----+-------------+----------------+---+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performing \"outer\" join operation with spark query \n",
    "person_DF.show(),program_DF.show()\n",
    "person_DF.join(program_DF,person_DF[\"graduate_program\"]==program_DF[\"id\"],\"outer\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Outer Join: Matches the keys in the left and right datasets and only keeps the rows from the left dataset. keeps the rows with keys in the left dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+\n",
      "| id| degree|school|\n",
      "+---+-------+------+\n",
      "|  0|Masters|   MIT|\n",
      "|  1|    PHD|   MIT|\n",
      "|  2|    PHD|   UCB|\n",
      "+---+-------+------+\n",
      "\n",
      "+---+-------------+----------------+\n",
      "| id|         name|graduate_program|\n",
      "+---+-------------+----------------+\n",
      "|  0|Bill chambers|               0|\n",
      "|  1|Matt Armbrust|               1|\n",
      "+---+-------------+----------------+\n",
      "\n",
      "+---+-------+------+----+-------------+----------------+\n",
      "| id| degree|school|  id|         name|graduate_program|\n",
      "+---+-------+------+----+-------------+----------------+\n",
      "|  0|Masters|   MIT|   0|Bill chambers|               0|\n",
      "|  1|    PHD|   MIT|   1|Matt Armbrust|               1|\n",
      "|  2|    PHD|   UCB|null|         null|            null|\n",
      "+---+-------+------+----+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# left outer join\n",
    "program_DF.show(),person_DF.show()\n",
    "program_DF.join(person_DF,person_DF[\"graduate_program\"]==program_DF[\"id\"],\"left_outer\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right outer join: Keeps the rows with keys in the right dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+\n",
      "| id| degree|school|\n",
      "+---+-------+------+\n",
      "|  0|Masters|   MIT|\n",
      "|  1|    PHD|   MIT|\n",
      "|  2|    PHD|   UCB|\n",
      "+---+-------+------+\n",
      "\n",
      "+---+-------------+----------------+\n",
      "| id|         name|graduate_program|\n",
      "+---+-------------+----------------+\n",
      "|  0|Bill chambers|               0|\n",
      "|  1|Matt Armbrust|               1|\n",
      "+---+-------------+----------------+\n",
      "\n",
      "+---+-------+------+---+-------------+----------------+\n",
      "| id| degree|school| id|         name|graduate_program|\n",
      "+---+-------+------+---+-------------+----------------+\n",
      "|  0|Masters|   MIT|  0|Bill chambers|               0|\n",
      "|  1|    PHD|   MIT|  1|Matt Armbrust|               1|\n",
      "+---+-------+------+---+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# right outer join\n",
    "program_DF.show(),person_DF.show()\n",
    "program_DF.join(person_DF,person_DF[\"graduate_program\"]==program_DF[\"id\"],\"right_outer\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left semi join: matches the keys and only keeps the rows with common keys in the left dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+\n",
      "| id| degree|school|\n",
      "+---+-------+------+\n",
      "|  0|Masters|   MIT|\n",
      "|  1|    PHD|   MIT|\n",
      "|  2|    PHD|   UCB|\n",
      "+---+-------+------+\n",
      "\n",
      "+---+-------------+----------------+\n",
      "| id|         name|graduate_program|\n",
      "+---+-------------+----------------+\n",
      "|  0|Bill chambers|               0|\n",
      "|  1|Matt Armbrust|               1|\n",
      "+---+-------------+----------------+\n",
      "\n",
      "+---+-------+------+\n",
      "| id| degree|school|\n",
      "+---+-------+------+\n",
      "|  0|Masters|   MIT|\n",
      "|  1|    PHD|   MIT|\n",
      "+---+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performing \"left semi\" join operation with spark query \n",
    "program_DF.show(),person_DF.show()\n",
    "program_DF.join(person_DF,person_DF[\"graduate_program\"]==program_DF[\"id\"],\"left_semi\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left anti join: works opposite to left semi join. compares the keys and keeps only those rows which donot match in the left dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+\n",
      "| id| degree|school|\n",
      "+---+-------+------+\n",
      "|  0|Masters|   MIT|\n",
      "|  1|    PHD|   MIT|\n",
      "|  2|    PHD|   UCB|\n",
      "+---+-------+------+\n",
      "\n",
      "+---+-------------+----------------+\n",
      "| id|         name|graduate_program|\n",
      "+---+-------------+----------------+\n",
      "|  0|Bill chambers|               0|\n",
      "|  1|Matt Armbrust|               1|\n",
      "+---+-------------+----------------+\n",
      "\n",
      "+---+------+------+\n",
      "| id|degree|school|\n",
      "+---+------+------+\n",
      "|  2|   PHD|   UCB|\n",
      "+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performing \"left anti\" join operation with spark query \n",
    "program_DF.show(),person_DF.show()\n",
    "program_DF.join(person_DF,person_DF[\"graduate_program\"]==program_DF[\"id\"],\"left_anti\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross join with Spark query\n",
    "c1_df=spark.createDataFrame([(\"a\"),\\\n",
    "                             (\"b\")],\"string\").toDF(\"C1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_df=spark.createDataFrame([(\"c\"),\\\n",
    "                             (\"d\"),\\\n",
    "                             (\"e\")],\"string\").toDF(\"C2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| C1|\n",
      "+---+\n",
      "|  a|\n",
      "|  b|\n",
      "+---+\n",
      "\n",
      "+---+\n",
      "| C2|\n",
      "+---+\n",
      "|  c|\n",
      "|  d|\n",
      "|  e|\n",
      "+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_df.show(),c2_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Cross join or cartesian: it is the cartesian product of both the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| C1|\n",
      "+---+\n",
      "|  a|\n",
      "|  b|\n",
      "+---+\n",
      "\n",
      "+---+\n",
      "| C2|\n",
      "+---+\n",
      "|  c|\n",
      "|  d|\n",
      "|  e|\n",
      "+---+\n",
      "\n",
      "+---+---+\n",
      "| C2| C1|\n",
      "+---+---+\n",
      "|  c|  a|\n",
      "|  c|  b|\n",
      "|  d|  a|\n",
      "|  d|  b|\n",
      "|  e|  a|\n",
      "|  e|  b|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Cross join\n",
    "c1_df.show(),c2_df.show()\n",
    "c2_df.crossJoin(c1_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing joins with SQL queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tempView for performing join through SQL queries\n",
    "person_DF.createOrReplaceTempView(\"person\")\n",
    "program_DF.createOrReplaceTempView(\"program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [id#203L, name#204, graduate_program#205L, degree#216, school#217]\n",
      "+- *(5) SortMergeJoin [graduate_program#205L, id#203L], [id#215L, id#215L], Inner\n",
      "   :- *(2) Sort [graduate_program#205L ASC NULLS FIRST, id#203L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(graduate_program#205L, id#203L, 200), ENSURE_REQUIREMENTS, [id=#756]\n",
      "   :     +- *(1) Project [_1#197L AS id#203L, _2#198 AS name#204, _3#199L AS graduate_program#205L]\n",
      "   :        +- *(1) Filter (((_1#197L = _3#199L) AND isnotnull(_3#199L)) AND isnotnull(_1#197L))\n",
      "   :           +- *(1) Scan ExistingRDD[_1#197L,_2#198,_3#199L]\n",
      "   +- *(4) Sort [id#215L ASC NULLS FIRST, id#215L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(id#215L, id#215L, 200), ENSURE_REQUIREMENTS, [id=#762]\n",
      "         +- *(3) Project [_1#209L AS id#215L, _2#210 AS degree#216, _3#211 AS school#217]\n",
      "            +- *(3) Filter isnotnull(_1#209L)\n",
      "               +- *(3) Scan ExistingRDD[_1#209L,_2#210,_3#211]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Natural Join\n",
    "# Left dataset= Person, Right dataset= program\n",
    "spark.sql(\"\"\"SELECT * FROM person NATURAL JOIN program WHERE (person.graduate_program)==(program.id) ;\"\"\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---+-------+------+\n",
      "| id|         name|graduate_program| id| degree|school|\n",
      "+---+-------------+----------------+---+-------+------+\n",
      "|  0|Bill chambers|               0|  0|Masters|   MIT|\n",
      "|  1|Matt Armbrust|               1|  1|    PHD|   MIT|\n",
      "+---+-------------+----------------+---+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inner Joins\n",
    "spark.sql(\"\"\"SELECT * FROM person INNER JOIN program ON (person.graduate_program)==(program.id) ;\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------------+---+-------+------+\n",
      "|  id|         name|graduate_program| id| degree|school|\n",
      "+----+-------------+----------------+---+-------+------+\n",
      "|   0|Bill chambers|               0|  0|Masters|   MIT|\n",
      "|   1|Matt Armbrust|               1|  1|    PHD|   MIT|\n",
      "|null|         null|            null|  2|    PHD|   UCB|\n",
      "+----+-------------+----------------+---+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Outer Join\n",
    "spark.sql(\"\"\"SELECT * FROM person FULL OUTER JOIN program ON program.id=person.graduate_program ;\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+----+-------------+----------------+\n",
      "| id| degree|school|  id|         name|graduate_program|\n",
      "+---+-------+------+----+-------------+----------------+\n",
      "|  0|Masters|   MIT|   0|Bill chambers|               0|\n",
      "|  1|    PHD|   MIT|   1|Matt Armbrust|               1|\n",
      "|  2|    PHD|   UCB|null|         null|            null|\n",
      "+---+-------+------+----+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Left Outer Join\n",
    "spark.sql(\"\"\"SELECT * FROM program LEFT OUTER JOIN person ON (program.id)=(person.graduate_program) ;\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+---+-------------+----------------+\n",
      "| id| degree|school| id|         name|graduate_program|\n",
      "+---+-------+------+---+-------------+----------------+\n",
      "|  0|Masters|   MIT|  0|Bill chambers|               0|\n",
      "|  1|    PHD|   MIT|  1|Matt Armbrust|               1|\n",
      "+---+-------+------+---+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# right outer\n",
    "spark.sql(\"\"\"SELECT * FROM program RIGHT OUTER JOIN person ON (program.id)=(person.graduate_program) ;\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+\n",
      "| id| degree|school|\n",
      "+---+-------+------+\n",
      "|  0|Masters|   MIT|\n",
      "|  1|    PHD|   MIT|\n",
      "+---+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# left semi\n",
    "spark.sql(\"\"\"SELECT * FROM program LEFT SEMI JOIN person ON (program.id)=(person.graduate_program) ;\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n",
      "| id|degree|school|\n",
      "+---+------+------+\n",
      "|  2|   PHD|   UCB|\n",
      "+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Left anti\n",
    "spark.sql(\"\"\"SELECT * FROM program LEFT ANTI JOIN person ON (program.id)=(person.graduate_program) ;\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Questions\n",
    "\n",
    "###  Pivot\n",
    "\n",
    "#### For this section, you are provided with the following retails dataset. Please use the dataset to answer the following question.\n",
    "\n",
    "Download the dataset from here: https://drive.google.com/file/d/13y81xA5ilsse4jE9HWtLkwf-3-_Lw3-1/view?usp=sharing\n",
    "\n",
    "If the link does not work, the dataset is available in the materials folder.\n",
    "\n",
    " \n",
    "\n",
    "Q: How many instances of each product were sold in each country?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retails_data=spark.read.csv(\"2010-12-01.json\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retails_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retails_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----+------+-------+-----------+------+--------------+\n",
      "|StockCode|Australia|EIRE|France|Germany|Netherlands|Norway|United Kingdom|\n",
      "+---------+---------+----+------+-------+-----------+------+--------------+\n",
      "|    10002|     null|null|    48|   null|       null|  null|            12|\n",
      "|    10125|     null|null|  null|   null|       null|  null|             2|\n",
      "|    10133|     null|null|  null|   null|       null|  null|             5|\n",
      "|    10135|     null|null|  null|   null|       null|  null|             1|\n",
      "|    11001|     null|null|  null|   null|       null|  null|             3|\n",
      "|   15044B|     null|null|  null|   null|       null|  null|             1|\n",
      "|  15056BL|     null|null|  null|   null|       null|  null|            20|\n",
      "|   15056N|     null|null|  null|   null|       null|  null|            50|\n",
      "|   15056P|     null|null|  null|   null|       null|  null|            48|\n",
      "|    16014|     null|null|  null|   null|       null|  null|            10|\n",
      "|    16016|     null|null|  null|   null|       null|  null|            10|\n",
      "|   16168M|     null|null|  null|   null|       null|  null|             2|\n",
      "|    16236|     null|null|  null|   null|       null|  null|             2|\n",
      "|    16237|     null|null|  null|   null|       null|  null|            70|\n",
      "|    16238|     null|null|  null|   null|       null|  null|            34|\n",
      "|   16258A|     null|null|  null|   null|       null|  null|             1|\n",
      "|    17003|     null|null|  null|   null|       null|  null|            39|\n",
      "|   17011F|     null|null|  null|   null|       null|  null|             1|\n",
      "|   17012A|     null|null|  null|   null|       null|  null|             4|\n",
      "|   17012B|     null|null|  null|   null|       null|  null|             3|\n",
      "+---------+---------+----+------+-------+-----------+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retails_data.groupBy(\"StockCode\").pivot(\"Country\").agg({\"Quantity\":\"sum\"}).orderBy(\"StockCode\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joins - Refer to the schema in the assignment\n",
    "\n",
    "The following schema describes customers who can place orders. Furthermore, there are employees who can convince customers to place an order. Not every order has to have a corresponding salesman. In this case, NULL is stored in the salesman id column. Employees can have supervisors. The orders table is the fact table and the other tables are dimensional tables. Use this schema for the following tasks. The DataFrames Customers, Orders, and Employees are available as variable and view with the names customers, orders, and employees respectively.\n",
    "\n",
    "    Q: Which employees could convince customers to order products?\n",
    "\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees=spark.createDataFrame([(0,\"John\",\"Brick\",\"DonJohn@abc.com\",\"01234\",\"23-01-2000\",20,\"HR\"),\\\n",
    "                                (1,\"Doe\",\"Moe\",\"DoeJoe@xyz.com\",\"345123\",\"03-07-2010\",20,\"Sales\")]).\\\n",
    "                                    toDF(\"Employee_ID\",\"First_name\",\"Last_name\",\"email\",\"phone\",\\\n",
    "                                         \"hire_date\",\"Manager_ID\",\"job_title\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders=spark.createDataFrame([(22,552,\"Availaible\",0,\"31-12-2021\"),\\\n",
    "                              (28,672,\"Availaible\",1,\"29-02-2020\"),\\\n",
    "                              (60,560,\"Not Availaible\",2,\"01-01-2021\")])\\\n",
    "                             .toDF(\"Order_ID\",\"customer_ID\",\"status\",\"salesman_ID\",\"order_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers=spark.createDataFrame([(560,\"rico\",\"new york\",\"na\",\"no limit\")\\\n",
    "                                ,(600,\"kayle\",\"Hamburg\",\"na\",\"exceeded\")\\\n",
    "                                ,(552,\"pepe\",\"barcelona\",\"na\",\"available\")]).toDF(\"customer_ID\",\"name\",\"address\",\"website\",\"credit_limit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+---------------+------+----------+----------+---------+\n",
      "|Employee_ID|First_name|Last_name|          email| phone| hire_date|Manager_ID|job_title|\n",
      "+-----------+----------+---------+---------------+------+----------+----------+---------+\n",
      "|          0|      John|    Brick|DonJohn@abc.com| 01234|23-01-2000|        20|       HR|\n",
      "|          1|       Doe|      Moe| DoeJoe@xyz.com|345123|03-07-2010|        20|    Sales|\n",
      "+-----------+----------+---------+---------------+------+----------+----------+---------+\n",
      "\n",
      "+--------+-----------+--------------+-----------+----------+\n",
      "|Order_ID|customer_ID|        status|salesman_ID|order_date|\n",
      "+--------+-----------+--------------+-----------+----------+\n",
      "|      22|        552|    Availaible|          0|31-12-2021|\n",
      "|      28|        672|    Availaible|          1|29-02-2020|\n",
      "|      60|        560|Not Availaible|          2|01-01-2021|\n",
      "+--------+-----------+--------------+-----------+----------+\n",
      "\n",
      "+-----------+-----+---------+-------+------------+\n",
      "|customer_ID| name|  address|website|credit_limit|\n",
      "+-----------+-----+---------+-------+------------+\n",
      "|        560| rico| new york|     na|    no limit|\n",
      "|        600|kayle|  Hamburg|     na|    exceeded|\n",
      "|        552| pepe|barcelona|     na|   available|\n",
      "+-----------+-----+---------+-------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employees.show(),orders.show(),customers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_expression=customers[\"customer_ID\"]==orders[\"customer_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_orders=orders.join(customers,join_expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+---------------+------+----------+----------+---------+\n",
      "|Employee_ID|First_name|Last_name|          email| phone| hire_date|Manager_ID|job_title|\n",
      "+-----------+----------+---------+---------------+------+----------+----------+---------+\n",
      "|          0|      John|    Brick|DonJohn@abc.com| 01234|23-01-2000|        20|       HR|\n",
      "|          1|       Doe|      Moe| DoeJoe@xyz.com|345123|03-07-2010|        20|    Sales|\n",
      "+-----------+----------+---------+---------------+------+----------+----------+---------+\n",
      "\n",
      "+--------+-----------+--------------+-----------+----------+-----------+----+---------+-------+------------+\n",
      "|Order_ID|customer_ID|        status|salesman_ID|order_date|customer_ID|name|  address|website|credit_limit|\n",
      "+--------+-----------+--------------+-----------+----------+-----------+----+---------+-------+------------+\n",
      "|      22|        552|    Availaible|          0|31-12-2021|        552|pepe|barcelona|     na|   available|\n",
      "|      60|        560|Not Availaible|          2|01-01-2021|        560|rico| new york|     na|    no limit|\n",
      "+--------+-----------+--------------+-----------+----------+-----------+----+---------+-------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employees.show(),customer_orders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_expression=employees[\"employee_ID\"]==customer_orders[\"salesman_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+---------------+-----+----------+----------+---------+\n",
      "|Employee_ID|First_name|Last_name|          email|phone| hire_date|Manager_ID|job_title|\n",
      "+-----------+----------+---------+---------------+-----+----------+----------+---------+\n",
      "|          0|      John|    Brick|DonJohn@abc.com|01234|23-01-2000|        20|       HR|\n",
      "+-----------+----------+---------+---------------+-----+----------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees.join(customer_orders,join_expression,\"leftsemi\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using sql query to join\n",
    "employees.createOrReplaceTempView(\"employees\")\n",
    "customers.createOrReplaceTempView(\"customers\")\n",
    "orders.createOrReplaceTempView(\"orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_orders=spark.sql(\"\"\"SELECT * FROM orders INNER JOIN customers\\\n",
    "                            ON (orders.customer_ID)=(customers.customer_ID) ;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_orders.createOrReplaceTempView(\"customer_orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(9) Project [_1#12198L AS Employee_ID#12214L, _2#12199 AS First_name#12215, _3#12200 AS Last_name#12216, _4#12201 AS email#12217, _5#12202 AS phone#12218, _6#12203 AS hire_date#12219, _7#12204L AS Manager_ID#12220L, _8#12205 AS job_title#12221]\n",
      "+- SortMergeJoin [_1#12198L], [salesman_ID#12243L], LeftSemi\n",
      "   :- *(2) Sort [_1#12198L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(_1#12198L, 200), ENSURE_REQUIREMENTS, [id=#1580]\n",
      "   :     +- *(1) Filter isnotnull(_1#12198L)\n",
      "   :        +- *(1) Scan ExistingRDD[_1#12198L,_2#12199,_3#12200,_4#12201,_5#12202,_6#12203,_7#12204L,_8#12205]\n",
      "   +- *(8) Sort [salesman_ID#12243L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(salesman_ID#12243L, 200), ENSURE_REQUIREMENTS, [id=#1599]\n",
      "         +- *(7) Project [salesman_ID#12243L]\n",
      "            +- *(7) SortMergeJoin [customer_ID#12241L], [customer_ID#12260L], Inner\n",
      "               :- *(4) Sort [customer_ID#12241L ASC NULLS FIRST], false, 0\n",
      "               :  +- Exchange hashpartitioning(customer_ID#12241L, 200), ENSURE_REQUIREMENTS, [id=#1585]\n",
      "               :     +- *(3) Project [_2#12231L AS customer_ID#12241L, _4#12233L AS salesman_ID#12243L]\n",
      "               :        +- *(3) Filter (isnotnull(_2#12231L) AND isnotnull(_4#12233L))\n",
      "               :           +- *(3) Scan ExistingRDD[_1#12230L,_2#12231L,_3#12232,_4#12233L,_5#12234]\n",
      "               +- *(6) Sort [customer_ID#12260L ASC NULLS FIRST], false, 0\n",
      "                  +- Exchange hashpartitioning(customer_ID#12260L, 200), ENSURE_REQUIREMENTS, [id=#1591]\n",
      "                     +- *(5) Project [_1#12250L AS customer_ID#12260L]\n",
      "                        +- *(5) Filter isnotnull(_1#12250L)\n",
      "                           +- *(5) Scan ExistingRDD[_1#12250L,_2#12251,_3#12252,_4#12253,_5#12254]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM employees LEFT SEMI JOIN customer_orders \\\n",
    "        ON (employees.Employee_ID)=(customer_orders.salesman_ID) ;\"\"\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
