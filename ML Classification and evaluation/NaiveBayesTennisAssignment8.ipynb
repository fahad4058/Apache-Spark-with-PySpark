{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "sqlcontext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------+-----+-----+\n",
      "| Outlook|Temperature|Humidity|Windy|Class|\n",
      "+--------+-----------+--------+-----+-----+\n",
      "|   sunny|        hot|    high|false|    n|\n",
      "|   sunny|        hot|    high| true|    n|\n",
      "|Overcast|        hot|    high|false|    p|\n",
      "|    rain|       mild|    high|false|    p|\n",
      "|    rain|       cool|  normal|false|    p|\n",
      "|    rain|       cool|  normal| true|    n|\n",
      "|Overcast|       cool|  normal| true|    p|\n",
      "|   sunny|       mild|    high|false|    n|\n",
      "|   sunny|       cool|  normal|false|    p|\n",
      "|    rain|       mild|  normal|false|    p|\n",
      "|   sunny|       mild|  normal| true|    p|\n",
      "|Overcast|       mild|    high| true|    p|\n",
      "|Overcast|        hot|  normal|false|    p|\n",
      "|    rain|       mild|    high| true|    n|\n",
      "|    rain|        hot|    high|false|    n|\n",
      "+--------+-----------+--------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "playtennisDf=spark.read.csv(\"playtennis1.csv\",header=True,inferSchema=True)\n",
    "playtennisDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tennisDf=playtennisDf.select(playtennisDf[\"Windy\"].cast(\"Integer\"),'Outlook', 'Temperature', 'Humidity','Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data=spark.createDataFrame([(0,\"rain\",\"hot\",\"high\")]).toDF(\"Windy\",\"Outlook\",\"Temperature\",\"Humidity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexing strings for tennisdf\n",
    "indexer_train=StringIndexer().setInputCols([\"Windy\",\"Outlook\",\"Temperature\",\"Humidity\",\"Class\"])\\\n",
    ".setOutputCols([\"Windy_ind\",\"Outlook_ind\",\"Temperature_ind\",\"Humidity_ind\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_tennisDF=indexer_train.fit(tennisDf).transform(tennisDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-----------+--------+-----+-----+---------+---------------+-----------+------------+\n",
      "|Windy| Outlook|Temperature|Humidity|Class|label|Windy_ind|Temperature_ind|Outlook_ind|Humidity_ind|\n",
      "+-----+--------+-----------+--------+-----+-----+---------+---------------+-----------+------------+\n",
      "|    0|   sunny|        hot|    high|    n|  1.0|      0.0|            1.0|        1.0|         0.0|\n",
      "|    1|   sunny|        hot|    high|    n|  1.0|      1.0|            1.0|        1.0|         0.0|\n",
      "|    0|Overcast|        hot|    high|    p|  0.0|      0.0|            1.0|        2.0|         0.0|\n",
      "|    0|    rain|       mild|    high|    p|  0.0|      0.0|            0.0|        0.0|         0.0|\n",
      "|    0|    rain|       cool|  normal|    p|  0.0|      0.0|            2.0|        0.0|         1.0|\n",
      "|    1|    rain|       cool|  normal|    n|  1.0|      1.0|            2.0|        0.0|         1.0|\n",
      "|    1|Overcast|       cool|  normal|    p|  0.0|      1.0|            2.0|        2.0|         1.0|\n",
      "|    0|   sunny|       mild|    high|    n|  1.0|      0.0|            0.0|        1.0|         0.0|\n",
      "|    0|   sunny|       cool|  normal|    p|  0.0|      0.0|            2.0|        1.0|         1.0|\n",
      "|    0|    rain|       mild|  normal|    p|  0.0|      0.0|            0.0|        0.0|         1.0|\n",
      "|    1|   sunny|       mild|  normal|    p|  0.0|      1.0|            0.0|        1.0|         1.0|\n",
      "|    1|Overcast|       mild|    high|    p|  0.0|      1.0|            0.0|        2.0|         0.0|\n",
      "|    0|Overcast|        hot|  normal|    p|  0.0|      0.0|            1.0|        2.0|         1.0|\n",
      "|    1|    rain|       mild|    high|    n|  1.0|      1.0|            0.0|        0.0|         0.0|\n",
      "|    0|    rain|        hot|    high|    n|  1.0|      0.0|            1.0|        0.0|         0.0|\n",
      "+-----+--------+-----------+--------+-----+-----+---------+---------------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed_tennisDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembling indep features with vectorassembler\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "va=VectorAssembler().setInputCols([\"Windy_ind\",\"Outlook_ind\",\"Temperature_ind\",\"Humidity_ind\"]).setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_DF=va.transform(indexed_tennisDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-----------+--------+-----+-----+---------+---------------+-----------+------------+-----------------+\n",
      "|Windy| Outlook|Temperature|Humidity|Class|label|Windy_ind|Temperature_ind|Outlook_ind|Humidity_ind|         features|\n",
      "+-----+--------+-----------+--------+-----+-----+---------+---------------+-----------+------------+-----------------+\n",
      "|    0|   sunny|        hot|    high|    n|  1.0|      0.0|            1.0|        1.0|         0.0|[0.0,1.0,1.0,0.0]|\n",
      "|    1|   sunny|        hot|    high|    n|  1.0|      1.0|            1.0|        1.0|         0.0|[1.0,1.0,1.0,0.0]|\n",
      "|    0|Overcast|        hot|    high|    p|  0.0|      0.0|            1.0|        2.0|         0.0|[0.0,2.0,1.0,0.0]|\n",
      "|    0|    rain|       mild|    high|    p|  0.0|      0.0|            0.0|        0.0|         0.0|        (4,[],[])|\n",
      "|    0|    rain|       cool|  normal|    p|  0.0|      0.0|            2.0|        0.0|         1.0|[0.0,0.0,2.0,1.0]|\n",
      "|    1|    rain|       cool|  normal|    n|  1.0|      1.0|            2.0|        0.0|         1.0|[1.0,0.0,2.0,1.0]|\n",
      "|    1|Overcast|       cool|  normal|    p|  0.0|      1.0|            2.0|        2.0|         1.0|[1.0,2.0,2.0,1.0]|\n",
      "|    0|   sunny|       mild|    high|    n|  1.0|      0.0|            0.0|        1.0|         0.0|    (4,[1],[1.0])|\n",
      "|    0|   sunny|       cool|  normal|    p|  0.0|      0.0|            2.0|        1.0|         1.0|[0.0,1.0,2.0,1.0]|\n",
      "|    0|    rain|       mild|  normal|    p|  0.0|      0.0|            0.0|        0.0|         1.0|    (4,[3],[1.0])|\n",
      "|    1|   sunny|       mild|  normal|    p|  0.0|      1.0|            0.0|        1.0|         1.0|[1.0,1.0,0.0,1.0]|\n",
      "|    1|Overcast|       mild|    high|    p|  0.0|      1.0|            0.0|        2.0|         0.0|[1.0,2.0,0.0,0.0]|\n",
      "|    0|Overcast|        hot|  normal|    p|  0.0|      0.0|            1.0|        2.0|         1.0|[0.0,2.0,1.0,1.0]|\n",
      "|    1|    rain|       mild|    high|    n|  1.0|      1.0|            0.0|        0.0|         0.0|    (4,[0],[1.0])|\n",
      "|    0|    rain|        hot|    high|    n|  1.0|      0.0|            1.0|        0.0|         0.0|    (4,[2],[1.0])|\n",
      "+-----+--------+-----------+--------+-----+-----+---------+---------------+-----------+------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=finalized_DF.randomSplit([0.8,0.2],1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.linalg import * #importing vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb=NaiveBayes(featuresCol=\"features\",labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nb.fit(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results=model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-----------+--------+-----+-----+--------------------+----------+\n",
      "|Windy| Outlook|Temperature|Humidity|Class|label|         probability|prediction|\n",
      "+-----+--------+-----------+--------+-----+-----+--------------------+----------+\n",
      "|    0|Overcast|        hot|  normal|    p|  0.0|[0.74052395776247...|       0.0|\n",
      "|    0|    rain|       mild|    high|    p|  0.0|[0.53333333333333...|       0.0|\n",
      "+-----+--------+-----------+--------+-----+-----+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.select(\"Windy\",\"Outlook\",\"Temperature\",\"Humidity\",\"Class\",\"label\",\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator=MulticlassClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy=evaluator.evaluate(pred_results)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false, rain, hot, high (0.0,0.0,2.0,0.0) DenseVector([0.0, 0.0, 2.0, 0.0]))\n",
    "# features rain=0.0,sunny=1.0,over=2.0    OUTLOOK\n",
    "#          false=0.0,true=1.0         Wind\n",
    "#          hot=2.0,mild=0.0,cool=1.0 Temperature \n",
    "#          high=0.0, normal=1.0        humidity \n",
    "\n",
    "#          format=wind,outlook,temp,humidity\n",
    "model.predict(DenseVector([0.0, 0.0, 2.0, 1.0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.6114, 0.3886])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predictProbability(DenseVector([0.0, 0.0, 2.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-4.5688, -5.0219])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predictRaw(DenseVector([0.0, 0.0, 2.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
